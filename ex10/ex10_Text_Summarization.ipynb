{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "prompt-inspector",
   "metadata": {},
   "source": [
    "# 텍스트 요약 : 뉴스기사 요약하기   \n",
    "\n",
    "## - 목차   \n",
    "\n",
    "1. 데이터 수집   \n",
    "2. 데이터 전처리 (추상적 요약)   \n",
    "3. 모델 설계   \n",
    "4. 어텐션 메커니즘 사용 (추상적 요약)  \n",
    "5. 모델 훈련\n",
    "6. 모델 테스트 : 실제 결과와 요약문 비교 (추상적 요약)   \n",
    "7. Summa 이용한 추출적 요약   \n",
    "- 프로젝트 결과"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-hughes",
   "metadata": {},
   "source": [
    "## 1. 데이터 수집"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "published-possession",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "employed-liability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61748</th>\n",
       "      <td>PokÃÂ©mon Go maker announces Harry Potter AR ...</td>\n",
       "      <td>Maker of the augmented reality (AR) game PokÃ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55169</th>\n",
       "      <td>Savings through Aadhaar-based DBT expected to ...</td>\n",
       "      <td>Finance Minister Arun Jaitley on Saturday said...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79988</th>\n",
       "      <td>Air India plans voluntary retirement scheme fo...</td>\n",
       "      <td>Air India is drawing up a proposal to offer vo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85837</th>\n",
       "      <td>I don't want to sing for any superstar: Diljit...</td>\n",
       "      <td>Singer Diljit Dosanjh has said he doesn't want...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33653</th>\n",
       "      <td>Would love to do a biopic on Rajesh Khanna, sa...</td>\n",
       "      <td>Pulkit Samrat has said he would love to do a b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62245</th>\n",
       "      <td>26 teenage girls found dead in Mediterranean Sea</td>\n",
       "      <td>Italy has launched an investigation into the d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93253</th>\n",
       "      <td>People in Mumbai clean 20,000 kg of trash</td>\n",
       "      <td>Nearly 100 residents of Kandivali in Mumbai ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24947</th>\n",
       "      <td>Misinterpreted: Minister who linked lynching t...</td>\n",
       "      <td>A day after he said the Alwar lynching inciden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90966</th>\n",
       "      <td>BJP workers forge Jayant Sinha's sign to dupe ...</td>\n",
       "      <td>BJP workers in Union Minister Jayant Sinha's c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42019</th>\n",
       "      <td>Too early to give prenuptial agreement legal b...</td>\n",
       "      <td>The government has said it is too early to giv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "61748  PokÃÂ©mon Go maker announces Harry Potter AR ...   \n",
       "55169  Savings through Aadhaar-based DBT expected to ...   \n",
       "79988  Air India plans voluntary retirement scheme fo...   \n",
       "85837  I don't want to sing for any superstar: Diljit...   \n",
       "33653  Would love to do a biopic on Rajesh Khanna, sa...   \n",
       "62245   26 teenage girls found dead in Mediterranean Sea   \n",
       "93253         People in Mumbai clean 20,000 kg of trash    \n",
       "24947  Misinterpreted: Minister who linked lynching t...   \n",
       "90966  BJP workers forge Jayant Sinha's sign to dupe ...   \n",
       "42019  Too early to give prenuptial agreement legal b...   \n",
       "\n",
       "                                                    text  \n",
       "61748  Maker of the augmented reality (AR) game PokÃ...  \n",
       "55169  Finance Minister Arun Jaitley on Saturday said...  \n",
       "79988  Air India is drawing up a proposal to offer vo...  \n",
       "85837  Singer Diljit Dosanjh has said he doesn't want...  \n",
       "33653  Pulkit Samrat has said he would love to do a b...  \n",
       "62245  Italy has launched an investigation into the d...  \n",
       "93253  Nearly 100 residents of Kandivali in Mumbai ca...  \n",
       "24947  A day after he said the Alwar lynching inciden...  \n",
       "90966  BJP workers in Union Minister Jayant Sinha's c...  \n",
       "42019  The government has said it is too early to giv...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bigger-assault",
   "metadata": {},
   "source": [
    "- 추상적 요약을 하는 경우에는 text를 본문, headlines를 이미 요약된 데이터로 모델을 학습하면 됨.\n",
    "- 추출적 요약을 하는 경우에는 오직 text열만을 사용해야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "weighted-imaging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "샘플 수  :  98401\n"
     ]
    }
   ],
   "source": [
    "print('샘플 수  : ', (len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "italic-continuity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines first data : \n",
      " upGrad learner switches to career in ML & Al with 90% salary hike\n",
      "text first data : \n",
      " Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.\n"
     ]
    }
   ],
   "source": [
    "print('headlines first data : \\n', data.loc[0]['headlines'])\n",
    "print('text first data : \\n', data.loc[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tracked-karaoke",
   "metadata": {},
   "source": [
    "## 2. 데이터 전처리 (추상적 요약)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fitted-nickel",
   "metadata": {},
   "source": [
    "### 2.1 중복값, 결측치 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "serious-average",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n",
      "headlines 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n"
     ]
    }
   ],
   "source": [
    "print('text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
    "print('headlines 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "sunset-touch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(subset = ['text'], inplace = True)\n",
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "solid-fourth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-convert",
   "metadata": {},
   "source": [
    "### 2.2 텍스트 정규화 및 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "labeled-slovak",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \",len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "republican-rouge",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 전처리 함수\n",
    "\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() #텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text #<br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) #괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) #쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) #약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) #소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) #영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) #m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    \n",
    "    # 불용어 미제거 (Summary)\n",
    "    #상대적으로 문장 길이가 짧은 Summary 전처리할 때는 호출하지 않음.\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "        \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "received-sessions",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "everything bought great infact ordered twice third ordered wasfor mother father\n",
      "great way to start the day\n"
     ]
    }
   ],
   "source": [
    "#데이터 전처리 함수 작동 확인\n",
    "temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n",
    "temp_summary = 'Great way to start (or finish) the day!!!'\n",
    "\n",
    "print(preprocess_sentence(temp_text))\n",
    "\n",
    "#Text의 경우에는 불용어를 제거하고, Summary의 경우에는 불용어를 제거하지 않음.\n",
    "print(preprocess_sentence(temp_summary, False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "regulated-mozambique",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185.0547275543213  seconds\n",
      "['saurav kant alumnus upgrad iiit pg program machine learning artificial intelligence sr systems engineer infosys almost years work experience program upgrad degree career support helped transition data scientist tech mahindra salary hike upgrad online power learning powered lakh careers'\n",
      " 'kunal shah credit card bill payment platform cred gave users chance win free food swiggy one year pranav kaushik delhi techie bagged reward spending cred coins users get one cred coin per rupee bill paid used avail rewards brands like ixigo bookmyshow ubereats cult fit'\n",
      " 'new zealand defeated india wickets fourth odi hamilton thursday win first match five match odi series india lost international match rohit sharma captaincy consecutive victories dating back march match witnessed india getting seventh lowest total odi cricket history'\n",
      " 'aegon life iterm insurance plan customers enjoy tax benefits premiums paid save taxes plan provides life cover age years also customers options insure critical illnesses disability accidental death benefit rider life cover age years'\n",
      " 'speaking sexual harassment allegations rajkumar hirani sonam kapoor said known hirani many years true metoo movement get derailed metoo movement always believe woman case need reserve judgment added hirani accused assistant worked sanju']\n",
      "5.896835088729858  seconds\n",
      "['upgrad learner switches to career in ml al with salary hike'\n",
      " 'delhi techie wins free food from swiggy for one year on cred'\n",
      " 'new zealand end rohit sharma led india match winning streak'\n",
      " 'aegon life iterm insurance plan helps customers save tax'\n",
      " 'have known hirani for yrs what if metoo claims are not true sonam']\n"
     ]
    }
   ],
   "source": [
    "### 멀티 프로세싱\n",
    "\n",
    "import multiprocessing as mp  \n",
    "from multiprocessing import Pool\n",
    "import numpy as np\n",
    "import time\n",
    "from functools import partial  #map을 할 때 함수에 여러 인자를 넣어줄 수 있도록 함.\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "#num_cores 만큼 쪼개진 데이터를 전처리하여 반환\n",
    "def appendTexts(sentences, remove_stopwords):\n",
    "  texts = []\n",
    "  for s in sentences:\n",
    "    texts += preprocess_sentence(s, remove_stopwords),\n",
    "  return texts\n",
    "\n",
    "def preprocess_data(data, remove_stopwords=True):\n",
    "  start_time = time.time()\n",
    "  num_cores = mp.cpu_count()  #컴퓨터의 코어 수\n",
    "\n",
    "  text_data_split = np.array_split(data, num_cores)  #코어 수만큼 데이터를 배분하여 병렬적으로 처리\n",
    "  pool = Pool(num_cores)\n",
    "\n",
    "  #각자 작업한 데이터를 하나로 합쳐줌.\n",
    "  processed_data = np.concatenate(pool.map(partial(appendTexts, remove_stopwords=remove_stopwords), text_data_split))\n",
    "  pool.close()\n",
    "  pool.join()\n",
    "  print(time.time() - start_time, \" seconds\")\n",
    "  return processed_data\n",
    "\n",
    "clean_text = preprocess_data(data['text'])\n",
    "print(clean_text[:5])\n",
    "\n",
    "#Summary에 대해서 전처리 함수를 호출해 줄 때는, 불용어 제거를 수행하지 않는다는 의미에서 두 번째 인자로 False 넣음.\n",
    "clean_headlines = preprocess_data(data['headlines'], remove_stopwords=False) \n",
    "print(clean_headlines[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "broken-production",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "headlines    0\n",
       "text         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#전처리 후 빈 샘플이 생겼는지 확인.\n",
    "#전처리 과정에서 문장의 모든 단어가 사라지는 경우가 있음.\n",
    "#빈 샘플이 있으면 모두 Null로 대체.\n",
    "\n",
    "data['text'] = clean_text\n",
    "data['headlines'] = clean_headlines\n",
    "\n",
    "# 빈 값을 Null 값으로 변환\n",
    "data.replace('', np.nan, inplace=True)\n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "interstate-equity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "print('전체 샘플수 :',(len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-graham",
   "metadata": {},
   "source": [
    "### 2.3 샘플 최대 길이 정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "saved-observer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 60\n",
      "텍스트의 평균 길이 : 35.09968483123221\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 16\n",
      "요약의 평균 길이 : 9.299532330215534\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "summary_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(summary_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(summary_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(summary_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(summary_len)\n",
    "plt.title('headlines')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('text')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('headlines')\n",
    "plt.hist(summary_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-atlanta",
   "metadata": {},
   "source": [
    "- 텍스트의 경우 최소 길이가 1, 최대 길이는 60, 평균 길이는 35로 그래프로 봤을 때 대체적으로 20 ~ 50 사이에 분포해 있음을 알 수 있다.\n",
    "- 헤드라인(요약)의 경우 최소 길이는 1, 최대 길이는 16, 평균 길이가 9로 그래프로 봤을 때 4 ~ 14 사이에 분포해 있음을 알 수 있다. \n",
    "- 위의 결과를 바탕으로 텍스트의 길이와 헤드라인의 적절한 최대 길이를 임의로 정할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "supreme-resident",
   "metadata": {},
   "outputs": [],
   "source": [
    "#위의 결과를 바탕으로 정한 임의의 최대 길이\n",
    "text_max_len = 45\n",
    "headlines_max_len = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "stone-cabin",
   "metadata": {},
   "outputs": [],
   "source": [
    "#위의 임의로 정한 길이들이 얼마나 객관적인지 통계로 확인\n",
    "\n",
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "modular-section",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 45 이하인 샘플의 비율: 0.9967771451809678\n",
      "전체 샘플 중 길이가 13 이하인 샘플의 비율: 0.9981699877999186\n"
     ]
    }
   ],
   "source": [
    "#임의의 길이가 몇%의 샘플까지 포함하는지 볼 수 있음.\n",
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(headlines_max_len,  data['headlines'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turned-revolution",
   "metadata": {},
   "source": [
    "- 비율을 봤을 때 임의로 정한 최대 길이가 나쁘지 않았음을 알 수 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "juvenile-status",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 97863\n"
     ]
    }
   ],
   "source": [
    "#정해진 길이에 맞춰 잘라내면 샘플들이 내용이 조금이라도 망가지기 때문에\n",
    "#자르는 것이 아닌 정해진 길이보다 길면 제외하는 방법으로 데이터 정제할 것.\n",
    "\n",
    "data = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['headlines'].apply(lambda x: len(x.split()) <= headlines_max_len)]\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moral-bradford",
   "metadata": {},
   "source": [
    "### 2.4 시작 토큰과 종료 토큰 추가\n",
    "- 시작 토큰은 sostoken, 종료 토큰은 eostoken이라 임의로 정하고 앞, 뒤로 추가함.\n",
    "- 디코더의 입력에 해당하면서 시작 토큰이 맨 앞에 있는 문장의 이름을 decoder_input\n",
    "- 디코더의 출력 또는 레이블에 해당되면서 종료 토큰이 맨 뒤에 붙는 문장의 이름을 decoder_target이라고 이름을 정함.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "received-jewelry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "      <td>saurav kant alumnus upgrad iiit pg program mac...</td>\n",
       "      <td>sostoken upgrad learner switches to career in ...</td>\n",
       "      <td>upgrad learner switches to career in ml al wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "      <td>kunal shah credit card bill payment platform c...</td>\n",
       "      <td>sostoken delhi techie wins free food from swig...</td>\n",
       "      <td>delhi techie wins free food from swiggy for on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "      <td>new zealand defeated india wickets fourth odi ...</td>\n",
       "      <td>sostoken new zealand end rohit sharma led indi...</td>\n",
       "      <td>new zealand end rohit sharma led india match w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "      <td>aegon life iterm insurance plan customers enjo...</td>\n",
       "      <td>sostoken aegon life iterm insurance plan helps...</td>\n",
       "      <td>aegon life iterm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>have known hirani for yrs what if metoo claims...</td>\n",
       "      <td>speaking sexual harassment allegations rajkuma...</td>\n",
       "      <td>sostoken have known hirani for yrs what if met...</td>\n",
       "      <td>have known hirani for yrs what if metoo claims...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upgrad learner switches to career in ml al wit...   \n",
       "1  delhi techie wins free food from swiggy for on...   \n",
       "2  new zealand end rohit sharma led india match w...   \n",
       "3  aegon life iterm insurance plan helps customer...   \n",
       "4  have known hirani for yrs what if metoo claims...   \n",
       "\n",
       "                                                text  \\\n",
       "0  saurav kant alumnus upgrad iiit pg program mac...   \n",
       "1  kunal shah credit card bill payment platform c...   \n",
       "2  new zealand defeated india wickets fourth odi ...   \n",
       "3  aegon life iterm insurance plan customers enjo...   \n",
       "4  speaking sexual harassment allegations rajkuma...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0  sostoken upgrad learner switches to career in ...   \n",
       "1  sostoken delhi techie wins free food from swig...   \n",
       "2  sostoken new zealand end rohit sharma led indi...   \n",
       "3  sostoken aegon life iterm insurance plan helps...   \n",
       "4  sostoken have known hirani for yrs what if met...   \n",
       "\n",
       "                                      decoder_target  \n",
       "0  upgrad learner switches to career in ml al wit...  \n",
       "1  delhi techie wins free food from swiggy for on...  \n",
       "2  new zealand end rohit sharma led india match w...  \n",
       "3  aegon life iterm insurance plan helps customer...  \n",
       "4  have known hirani for yrs what if metoo claims...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#headlines 데이터에 시작 토큰과 종료 토큰을 추가.\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "qualified-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#인코더의 입력, 디코더의 입력 후 레이블을 다시 numpy 타입으로 저장.\n",
    "\n",
    "#인코더의 입력\n",
    "encoder_input = np.array(data['text']) \n",
    "\n",
    "#디코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) \n",
    "\n",
    "#디코더의 레이블\n",
    "decoder_target = np.array(data['decoder_target']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "saving-funds",
   "metadata": {},
   "source": [
    "### 2.5 데이터셋 분리\n",
    "- 훈련 데이터와 테스트 데이터 분리.\n",
    "- 직접 코딩을 통해 분리할 예정."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sharp-national",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46844 24653 21980 ...  5902 72806 57833]\n",
      "indices len : 97863\n"
     ]
    }
   ],
   "source": [
    "#encoder_input과 크기, 형태가 같은 순서가 섞인 정수 시퀀스를 형성.\n",
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)\n",
    "print('indices len :', len(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "designing-consumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "#위의 정수 시퀀스를 이용해 데이터 샘플 순서를 정의하여 샘플을 섞음.\n",
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "realistic-overview",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 19572\n"
     ]
    }
   ],
   "source": [
    "#섞은 데이터를 8:2의 비율로 분리\n",
    "#전체 데이터의 크기에서 0.2를 곱해 테스트 데이터의 크기를 정의.\n",
    "\n",
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :', n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "behind-scanning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 78291\n",
      "훈련 레이블의 개수 : 78291\n",
      "테스트 데이터의 개수 : 19572\n",
      "테스트 레이블의 개수 : 19572\n"
     ]
    }
   ],
   "source": [
    "#위에서 정의한 테스트 데이터의 개수를 이용해 전체 데이터를 양분\n",
    "\n",
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sophisticated-liquid",
   "metadata": {},
   "source": [
    "### 2.6 단어 집합(vocabulary) 생성 및 정수 인코딩\n",
    "- 단어 집합 : 각 단어에 고유한 정수 맵핑\n",
    "- Keras의 토크나이저를 사용하면, 입력된 훈련 데이터로부터 단어 집합을 만들 수 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-bundle",
   "metadata": {},
   "source": [
    "#### - 텍스트 단어 집합 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "statutory-butler",
   "metadata": {},
   "outputs": [],
   "source": [
    "#토크나이저 정의\n",
    "src_tokenizer = Tokenizer() \n",
    "\n",
    "#입력된 데이터로부터 단어 집합 생성\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "stylish-taylor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 69257\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 47128\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 22129\n",
      "단어 집합에서 희귀 단어의 비율: 68.04799514850485\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.479532089180063\n"
     ]
    }
   ],
   "source": [
    "#빈도수가 낮은 단어들은 훈련 데이터에서 제외하고 진행.\n",
    "\n",
    "#등장 빈도수가 7회 미만인 단어들이 데이터에서 얼마나 차지하는지 확인\n",
    "#src_tokenizer.word_counts.items()로 통계적인 정보를 얻을 수 있음.\n",
    "\n",
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) #단어의 수\n",
    "rare_cnt = 0 #등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 #훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 #등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "#단어와 빈도수의 쌍(pair)을 key와 value로 받음.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    #단어의 등장 빈도수가 threshold보다 작을 때\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-secondary",
   "metadata": {},
   "source": [
    "- 단어 집합(vocabulary)의 크기는 약 7만임.\n",
    "- 등장 빈도가 threshold 값인 7회 미만, 즉, 6회 이하인 단어들은 단어 집합에서 약 68%를 차지함.\n",
    "- 실제로 훈련 데이터에서 등장 빈도로 차지하는 비중은 상대적으로 적은 수치인 약 3.5%임.\n",
    "- 등장 빈도가 6회 이하인 단어들은 정수 인코딩 과정에서 빼고, 훈련 데이터에서 제거하는 것이 좋음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "secondary-roads",
   "metadata": {},
   "outputs": [],
   "source": [
    "#위에서 제외한 단어 집합 크기를 약 2만 2천여개로 계산했는데 이와 비슷한 값으로 단어 집합 크기를 제한할 것.\n",
    "#토크나이저 정의 시 num_words의 값을 정하면 단어 집합의 크기를 제한할 수 있음.\n",
    "\n",
    "src_vocab = 22000\n",
    "\n",
    "#단어 집합의 크기를 22,000으로 제한\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) \n",
    "\n",
    "#단어 집합 재생성.\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "patient-huntington",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2604, 2724, 18277, 764, 3, 13, 19, 198, 1532, 9109, 3601, 6170, 1219, 5, 8141, 80, 1902, 88, 28, 267, 5315, 18278, 228, 198, 1219, 18277, 1532, 1500, 855, 29, 3, 19, 1902, 592], [132, 708, 2754, 313, 837, 3211, 3982, 2466, 5259, 440, 4834, 107, 1450, 440, 3295, 107, 5925, 15963, 908, 2466, 263, 3982, 7776, 794, 1670, 2228, 949, 108, 837, 1484, 1257, 3128, 9275, 432], [653, 222, 252, 97, 124, 5467, 2652, 970, 3423, 695, 105, 196, 309, 1, 516, 1, 2618, 927, 759, 4, 1116, 271, 5806, 1275, 1046, 653, 277, 11234, 1]]\n"
     ]
    }
   ],
   "source": [
    "#텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "#잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wooden-production",
   "metadata": {},
   "source": [
    "- texts_to_sequences()는 생성된 단어 집합에 기반하여 입력으로 주어진 텍스트 데이터의 단어들을 모두 정수로 변환하는 정수 인코딩을 수행.\n",
    "- 22,000이 넘는 숫자들은 정수 인코딩 후에는 데이터에 존재하지 않게 됨."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "matched-parade",
   "metadata": {},
   "source": [
    "#### - headlines 단어 집합 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "sticky-length",
   "metadata": {},
   "outputs": [],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "former-consciousness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 29989\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 20475\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 9514\n",
      "단어 집합에서 희귀 단어의 비율: 68.27503417919904\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 5.305387809313382\n"
     ]
    }
   ],
   "source": [
    "hreshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) #단어의 수\n",
    "rare_cnt = 0 #등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 #훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 #등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "#단어와 빈도수의 쌍(pair)을 key와 value로 받음.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    #단어의 등장 빈도수가 threshold보다 작을 때\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocal-addiction",
   "metadata": {},
   "source": [
    "- 단어 집합(vocabulary)의 크기는 약 3만임.\n",
    "- 등장 빈도가 threshold 값인 6회 미만, 즉, 5회 이하인 단어들은 단어 집합에서 약 68%를 차지함.\n",
    "- 전체 등장 빈도에서 희귀 단어 등장 빈도 비율은 약 5.3%임.\n",
    "- 등장 빈도가 5회 이하인 단어들은 정수 인코딩 과정에서 빼고, 훈련 데이터에서 제거하는 것이 좋음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "applicable-conditioning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input : \n",
      "input  [[1, 61, 26, 313, 4, 1670, 431, 61, 26, 29, 108], [1, 410, 1818, 53, 4983, 1965, 5392, 4, 1168, 5890], [1, 362, 396, 72, 466, 179, 18, 76, 338, 81, 323], [1, 2837, 1045, 1520, 1392, 1929, 1348, 9, 3895], [1, 8751, 3086, 8172, 292, 7668, 118, 1255, 2626]]\n",
      "target : \n",
      "decoder  [[61, 26, 313, 4, 1670, 431, 61, 26, 29, 108, 2], [410, 1818, 53, 4983, 1965, 5392, 4, 1168, 5890, 2], [362, 396, 72, 466, 179, 18, 76, 338, 81, 323, 2], [2837, 1045, 1520, 1392, 1929, 1348, 9, 3895, 2], [8751, 3086, 8172, 292, 7668, 118, 1255, 2626, 2]]\n"
     ]
    }
   ],
   "source": [
    "#위에서 제외한 단어 집합 크기를 약 9천5백개로 계산했는데 이와 비슷한 값으로 단어 집합 크기를 제한할 것.\n",
    "tar_vocab = 9500\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "#텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "#잘 변환되었는지 확인\n",
    "print('input : ')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target : ')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "standard-athens",
   "metadata": {},
   "source": [
    "- 전체 데이터에서 빈도수가 낮은 단어가 삭제되었다는 것은 빈도수가 낮은 단어만으로 구성되었던 샘플들은 이제 빈(empty) 샘플이 되었을 가능성이 있음.\n",
    "- 평균 길이가 짧았던 headline은 더욱 심할 것.\n",
    "- decoder_input에는 sostoken 또는 decoder_target에는 eostoken이 추가된 상태이고, 이 두 토큰은 모든 샘플에서 등장하므로 빈도수가 샘플 수와 동일하게 매우 높으므로 단어 집합 제한에도 삭제되지 않음. 그래서 이제 길이가 0이 된 요약문의 실제 길이는 1로 나올 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "equipped-induction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 1\n",
      "삭제할 테스트 데이터의 개수 : 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 78290\n",
      "훈련 레이블의 개수 : 78290\n",
      "테스트 데이터의 개수 : 19572\n",
      "테스트 레이블의 개수 : 19572\n"
     ]
    }
   ],
   "source": [
    "#요약문에서 길이가 0이 된 샘플들의 인덱스를 받아 \n",
    "#훈련 데이터와 테스트 데이터에 대해서 요약문의 길이가 1인 경우의 인덱스를 \n",
    "#각각 drop_train과 drop_test에 라는 변수에 저장 후 이 샘플들을 모두 삭제.\n",
    "\n",
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n",
    "decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n",
    "decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n",
    "\n",
    "encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n",
    "decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n",
    "decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valuable-presentation",
   "metadata": {},
   "source": [
    "### 2.7 패딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ongoing-fancy",
   "metadata": {},
   "outputs": [],
   "source": [
    "#서로 다른 길이의 샘플들을 병렬 처리하기 위해 같은 길이로 맞춰줌.\n",
    "#최대 길이보다 짧은 데이터들은 뒤의 공간에 숫자 0을 넣어 최대 길이로 길이를 맞춤.\n",
    "\n",
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=headlines_max_len, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-league",
   "metadata": {},
   "source": [
    "## 3. 모델 설계"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bearing-metallic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "#인코더 설계 시작\n",
    "#임베딩 벡터의 차원은 128로 정의하고, hidden state의 크기를 256으로 정의\n",
    "embedding_dim = 128\n",
    "hidden_size = 256   # hidden state는 LSTM에서 얼만큼의 수용력(capacity)를 가질지를 정하는 파라미터\n",
    "                    #이 파라미터는 LSTM의 용량의 크기나, LSTM에서의 뉴런의 개수로 이해하면 됨.\n",
    "#인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "#인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "#인코더의 LSTM은 총 3개의 층으로 구성해서 모델의 복잡도를 높임.\n",
    "#인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "#인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "#인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "capable-mississippi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "#디코더의 임베딩 층과 LSTM을 설계하는 것은 인코더와 거의 동일함.\n",
    "#LSTM 입력 정의 시 initial_state의 인자값으로 인코더의 hidden state와 ceel state의 값을 넣어줘야 함.\n",
    "\n",
    "#디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "#디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "#디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "extended-responsibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 45)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 45, 128)      2816000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 45, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 45, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1216000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 45, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 9500)   2441500     lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 8,312,604\n",
      "Trainable params: 8,312,604\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "#모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-italy",
   "metadata": {},
   "source": [
    "- 디코더의 출력층에서는 Summary의 단어장인 tar_vocab의 수많은 선택지 중 하나의 단어를 선택하는 다중 클래스 분류 문제를 풀어야하기 때문에 Dense의 인자로 tar_vocab을 주고, 활성화 함수로 소프트맥스 함수를 사용함.\n",
    "\n",
    "- 지금까지 설계한 것은 인코더의 hidden state와 cell state를 디코더의 초기 state로 사용하는 가장 기본적인 seq2seq임."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "packed-poland",
   "metadata": {},
   "source": [
    "## 4. 어텐션 메커니즘 (추상적 요약)\n",
    "- 디코더의 출력층을 설계를 살짝 바꿔서 성능을 높일 수 있는 방법이지만 또 다른 새로운 신경망을 설계해야 한다는 뜻이기도 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "surprised-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#깃허브에 공개 되어 있는 어텐션 함수 다운\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/thushv89/attention_keras/master/src/layers/attention.py\", filename=\"attention.py\")\n",
    "from attention import AttentionLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "premier-jefferson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 45)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 45, 128)      2816000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 45, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 45, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    1216000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 45, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer ((None, None, 256),  131328      lstm_2[0][0]                     \n",
      "                                                                 lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 9500)   4873500     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 10,875,932\n",
      "Trainable params: 10,875,932\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "###디코더의 출력층 수정\n",
    "\n",
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AttentionLayer(name='attention_layer')\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-restaurant",
   "metadata": {},
   "source": [
    "- 위의 코드는 인코더의 hidden state들과 디코더의 hidden state들을 어텐션 함수의 입력으로 사용하고, 어텐션 함수가 리턴한 값을 예측 시에 디코더의 hidden state와 함께 활용하는 형태로 작동함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-teacher",
   "metadata": {},
   "source": [
    "## 5. 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "physical-beaver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "306/306 [==============================] - 236s 735ms/step - loss: 5.5862 - val_loss: 4.8140\n",
      "Epoch 2/50\n",
      "306/306 [==============================] - 223s 730ms/step - loss: 4.7464 - val_loss: 4.4315\n",
      "Epoch 3/50\n",
      "306/306 [==============================] - 221s 722ms/step - loss: 4.3677 - val_loss: 4.1709\n",
      "Epoch 4/50\n",
      "306/306 [==============================] - 221s 721ms/step - loss: 4.1048 - val_loss: 3.9941\n",
      "Epoch 5/50\n",
      "306/306 [==============================] - 222s 726ms/step - loss: 3.8985 - val_loss: 3.8706\n",
      "Epoch 6/50\n",
      "306/306 [==============================] - 221s 721ms/step - loss: 3.7253 - val_loss: 3.7657\n",
      "Epoch 7/50\n",
      "306/306 [==============================] - 220s 720ms/step - loss: 3.5900 - val_loss: 3.6765\n",
      "Epoch 8/50\n",
      "306/306 [==============================] - 221s 721ms/step - loss: 3.4653 - val_loss: 3.6156\n",
      "Epoch 9/50\n",
      "306/306 [==============================] - 221s 724ms/step - loss: 3.3634 - val_loss: 3.5531\n",
      "Epoch 10/50\n",
      "306/306 [==============================] - 220s 720ms/step - loss: 3.2714 - val_loss: 3.5018\n",
      "Epoch 11/50\n",
      "306/306 [==============================] - 221s 722ms/step - loss: 3.1826 - val_loss: 3.4622\n",
      "Epoch 12/50\n",
      "306/306 [==============================] - 220s 720ms/step - loss: 3.1025 - val_loss: 3.4272\n",
      "Epoch 13/50\n",
      "306/306 [==============================] - 221s 723ms/step - loss: 3.0370 - val_loss: 3.4020\n",
      "Epoch 14/50\n",
      "306/306 [==============================] - 221s 723ms/step - loss: 2.9804 - val_loss: 3.3766\n",
      "Epoch 15/50\n",
      "306/306 [==============================] - 220s 720ms/step - loss: 2.9209 - val_loss: 3.3554\n",
      "Epoch 16/50\n",
      "306/306 [==============================] - 221s 722ms/step - loss: 2.8580 - val_loss: 3.3362\n",
      "Epoch 17/50\n",
      "306/306 [==============================] - 220s 720ms/step - loss: 2.8105 - val_loss: 3.3197\n",
      "Epoch 18/50\n",
      "306/306 [==============================] - 221s 722ms/step - loss: 2.7643 - val_loss: 3.3057\n",
      "Epoch 19/50\n",
      "306/306 [==============================] - 220s 719ms/step - loss: 2.7180 - val_loss: 3.2921\n",
      "Epoch 20/50\n",
      "306/306 [==============================] - 222s 726ms/step - loss: 2.6814 - val_loss: 3.2816\n",
      "Epoch 21/50\n",
      "306/306 [==============================] - 222s 727ms/step - loss: 2.6421 - val_loss: 3.2722\n",
      "Epoch 22/50\n",
      "306/306 [==============================] - 221s 722ms/step - loss: 2.6009 - val_loss: 3.2640\n",
      "Epoch 23/50\n",
      "306/306 [==============================] - 221s 723ms/step - loss: 2.5726 - val_loss: 3.2537\n",
      "Epoch 24/50\n",
      "306/306 [==============================] - 223s 727ms/step - loss: 2.5362 - val_loss: 3.2546\n",
      "Epoch 25/50\n",
      "306/306 [==============================] - 222s 726ms/step - loss: 2.5031 - val_loss: 3.2490\n",
      "Epoch 26/50\n",
      "306/306 [==============================] - 222s 727ms/step - loss: 2.4764 - val_loss: 3.2450\n",
      "Epoch 27/50\n",
      "306/306 [==============================] - 223s 728ms/step - loss: 2.4510 - val_loss: 3.2363\n",
      "Epoch 28/50\n",
      "306/306 [==============================] - 222s 726ms/step - loss: 2.4227 - val_loss: 3.2415\n",
      "Epoch 29/50\n",
      "306/306 [==============================] - 222s 726ms/step - loss: 2.3970 - val_loss: 3.2395\n",
      "Epoch 00029: early stopping\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "#val_loss(검증 데이터의 손실)을 관찰하다가, \n",
    "#검증 데이터의 손실이 줄어들지 않고 증가하는 현상이 2회(patience=2) 관측되면 학습을 멈추도록 설정\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', patience=2, verbose=1)\n",
    "\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[es], epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "induced-vanilla",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#훈련 데이터의 손실과 검증 데이터의 손실이 줄어드는 과정 시각화\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-tunisia",
   "metadata": {},
   "source": [
    "## 6. 모델 테스트 : 실제 결과와 요약문 비교 (추상적 요약)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-march",
   "metadata": {},
   "source": [
    "### 6.1 인퍼런스 모델 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "turned-norway",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 필요한 사전 3개 준비\n",
    "\n",
    "#원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "src_index_to_word = src_tokenizer.index_word\n",
    "\n",
    "#요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index\n",
    "\n",
    "#요약 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-minnesota",
   "metadata": {},
   "source": [
    "- seq2seq는 훈련할 때와 실제 동작할 때(인퍼런스 단계)의 방식이 다르므로 그에 맞게 모델 설계를 별개로 진행해야 함.\n",
    "- 정답 문장이 없는 인퍼런스 단계에서는 만들어야 할 문장의 길이만큼 디코더가 반복 구조로 동작해야 하기 때문에 부득이하게 인퍼런스를 위한 모델 설계를 별도로 해주어야 함.\n",
    "- 때문에 인코더 모델과 디더 모델을 분리해서 설계함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "significant-father",
   "metadata": {},
   "outputs": [],
   "source": [
    "#인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "#이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "#문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "#훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "noted-assist",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 어텐션 메커니즘 사용하는 출력층 설계\n",
    "\n",
    "#어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "#디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "#최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "rural-minnesota",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 인퍼런스 단계에서 단어 시퀀스를 완성하는 함수\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    #입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "    #<SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: #stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        # <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (headlines_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        #길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        #상태 업데이트\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-diabetes",
   "metadata": {},
   "source": [
    "### 6.2 원문과 요약문 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "commercial-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 원문의 정수 시퀀스를 텍스트 시퀀스로 변환하는 함수\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "#요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if ((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atmospheric-stress",
   "metadata": {},
   "source": [
    "- Text의 정수 시퀀스에서는 패딩을 위해 사용되는 숫자 0을 제외하고 Summary의 정수 시퀀스에서는 숫자 0, 시작 토큰의 인덱스, 종료 토큰의 인덱스를 출력에서 제외하도록 만들어야 함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "smaller-jacob",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : \n",
      "  three twelve boys trapped cave northern thailand days granted thai citizenship wednesday boys despite born thailand lack citizenship deprived basic benefits rights three applied citizenship cave incident \n",
      "실제 요약 : \n",
      "  boys rescued from thai cave granted citizenship \n",
      "예측 요약 : \n",
      "   thai cave rescued from thai cave to rescue boys\n",
      "\n",
      "\n",
      "원문 : \n",
      "  nasa mars reconnaissance orbiter spotted space agency opportunity rover dust storm red planet opportunity last communicated june operating since nasa oldest active rover nasa hoping solar powered rover contact earth batteries charged exposure sunlight \n",
      "실제 요약 : \n",
      "  nasa mars spots silent rover as dust storm clears \n",
      "예측 요약 : \n",
      "   nasa rover rover on mars days to mars\n",
      "\n",
      "\n",
      "원문 : \n",
      "  us president donald trump told friends got lot richer hours signed tax cut bill proposed us biggest tax overhaul years law friday report claimed legislation estimated cost us lakh crore cuts corporate tax rate \n",
      "실제 요약 : \n",
      "  trump told friends they got lot richer after tax cut report \n",
      "예측 요약 : \n",
      "   trump will not tax tax on tax tax hike\n",
      "\n",
      "\n",
      "원문 : \n",
      "  goair flight srinagar jammu reached destination sunday without baggage several passengers goair staffer told passengers luggage would brought jammu another flight airlines waiting hour told come collect luggage tomorrow one passengers said \n",
      "실제 요약 : \n",
      "  goair flight from srinagar lands in jammu without baggage \n",
      "예측 요약 : \n",
      "   pilot leaves emergency after flight passengers fall ill\n",
      "\n",
      "\n",
      "원문 : \n",
      "  white house aide kelly reportedly mocked cancer stricken us senator john mccain opposition cia director nominee gina haspel saying matter dying anyway republican senator arizona diagnosed brain cancer cia director nominee haspel facing opposition involvement torture al qaeda suspects \n",
      "실제 요약 : \n",
      "  he dying wh aide mocks cancer senator \n",
      "예측 요약 : \n",
      "   us house asks us to remove trump from cancer poisoning\n",
      "\n",
      "\n",
      "원문 : \n",
      "  hollywood actress amber heard slammed posting racist tweet advising people give ride home immigration checkpoint near house heard criticising us government crackdown illegal migrants later deleted tweet following public backlash \n",
      "실제 요약 : \n",
      "  amber heard slammed for racist tweet \n",
      "예측 요약 : \n",
      "   jennifer slams ex cm for posting her videos\n",
      "\n",
      "\n",
      "원문 : \n",
      "  stephen hawking funeral took place march cambridge uk great st mary church thousands attended pay tribute world renowned physicist church bells rang times representing number years hawking lived coffin carried six college hawking fellow years \n",
      "실제 요약 : \n",
      "  thousands attend stephen hawking funeral in uk \n",
      "예측 요약 : \n",
      "   stephen hawking passes away at the age of\n",
      "\n",
      "\n",
      "원문 : \n",
      "  pakistan monday began auction vehicles prime minister house part prime minister imran khan led government cost cutting drive fleet cars put auction includes mercedes cars including bullet proof ones auction expected fetch nearly pkr billion \n",
      "실제 요약 : \n",
      "  pakistan auctions vehicles of prime minister house \n",
      "예측 요약 : \n",
      "   pakistan pm nawaz sharif car sold for lakh\n",
      "\n",
      "\n",
      "원문 : \n",
      "  ahead th anniversary operation blue star akal takht singh friday appealed sikh bodies observe day peacefully avoid sloganeering inside amritsar golden temple past years anniversary marred violence sloganeering inside temple support khalistan movement \n",
      "실제 요약 : \n",
      "  do not slogans on op blue star anniversary takht \n",
      "예측 요약 : \n",
      "   india first lady to get statue in day of march\n",
      "\n",
      "\n",
      "원문 : \n",
      "  lok sabha speaker sumitra mahajan organised screening aamir khan film dangal members parliament requested official mps attend screening spouses screening held parliament march spread message women empowerment mps promote constituencies \n",
      "실제 요약 : \n",
      "  govt asks mps to attend dangal screening with \n",
      "예측 요약 : \n",
      "   lok sabha mps to be in parliament tdp\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#실제 요약과 예측된 요약 비교\n",
    "for i in range(10):\n",
    "    print(\"원문 : \\n \", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 : \\n \", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 : \\n \", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-mexico",
   "metadata": {},
   "source": [
    "## 7. Summa 이용한 추출적 요약\n",
    "- 패키지 Summa에서는 추출적 요약을 위한 모듈인 summarize를 제공하고 있음.\n",
    "- text (str) : 요약할 테스트.\n",
    "- ratio (float, optional) – 요약문에서 원본에서 선택되는 문장 비율. 0~1 사이값\n",
    "- words (int or None, optional) – 출력에 포함할 단어 수.\n",
    "- split (bool, optional) – True면 문장 list / False는 조인(join)된 문자열을 반환.\n",
    "- Summa의 summarize는 문장 토큰화를 별도로 하지 않더라도 내부적으로 문장 토큰화를 수행."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "hispanic-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "orig_data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "portable-short",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "원문 : \n",
      "  Saurav Kant, an alumnus of upGrad and IIIT-B's PG Program in Machine learning and Artificial Intelligence, was a Sr Systems Engineer at Infosys with almost 5 years of work experience. The program and upGrad's 360-degree career support helped him transition to a Data Scientist at Tech Mahindra with 90% salary hike. upGrad's Online Power Learning has powered 3 lakh+ careers.\n",
      "실제 요약 : \n",
      "  upGrad learner switches to career in ML & Al with 90% salary hike\n",
      "예측 요약 : \n",
      "  upGrad's Online Power Learning has powered 3 lakh+ careers.\n",
      "\n",
      "\n",
      "원문 : \n",
      "  Kunal Shah's credit card bill payment platform, CRED, gave users a chance to win free food from Swiggy for one year. Pranav Kaushik, a Delhi techie, bagged this reward after spending 2000 CRED coins. Users get one CRED coin per rupee of bill paid, which can be used to avail rewards from brands like Ixigo, BookMyShow, UberEats, Cult.Fit and more.\n",
      "실제 요약 : \n",
      "  Delhi techie wins free food from Swiggy for one year on CRED\n",
      "예측 요약 : \n",
      "  Users get one CRED coin per rupee of bill paid, which can be used to avail rewards from brands like Ixigo, BookMyShow, UberEats, Cult.Fit and more.\n",
      "\n",
      "\n",
      "원문 : \n",
      "  New Zealand defeated India by 8 wickets in the fourth ODI at Hamilton on Thursday to win their first match of the five-match ODI series. India lost an international match under Rohit Sharma's captaincy after 12 consecutive victories dating back to March 2018. The match witnessed India getting all out for 92, their seventh lowest total in ODI cricket history.\n",
      "실제 요약 : \n",
      "  New Zealand end Rohit Sharma-led India's 12-match winning streak\n",
      "예측 요약 : \n",
      "  The match witnessed India getting all out for 92, their seventh lowest total in ODI cricket history.\n",
      "\n",
      "\n",
      "원문 : \n",
      "  With Aegon Life iTerm Insurance plan, customers can enjoy tax benefits on your premiums paid and save up to Ã¢ÂÂ¹46,800^ on taxes. The plan provides life cover up to the age of 100 years. Also, customers have options to insure against Critical Illnesses, Disability and Accidental Death Benefit Rider with a life cover up to the age of 80 years.\n",
      "실제 요약 : \n",
      "  Aegon life iTerm insurance plan helps customers save tax\n",
      "예측 요약 : \n",
      "  Also, customers have options to insure against Critical Illnesses, Disability and Accidental Death Benefit Rider with a life cover up to the age of 80 years.\n",
      "\n",
      "\n",
      "원문 : \n",
      "  Speaking about the sexual harassment allegations against Rajkumar Hirani, Sonam Kapoor said, \"I've known Hirani for many years...What if it's not true, the [#MeToo] movement will get derailed.\" \"In the #MeToo movement, I always believe a woman. But in this case, we need to reserve our judgment,\" she added. Hirani has been accused by an assistant who worked in 'Sanju'.\n",
      "실제 요약 : \n",
      "  Have known Hirani for yrs, what if MeToo claims are not true: Sonam\n",
      "예측 요약 : \n",
      "  Speaking about the sexual harassment allegations against Rajkumar Hirani, Sonam Kapoor said, \"I've known Hirani for many years...What if it's not true, the [#MeToo] movement will get derailed.\" \"In the #MeToo movement, I always believe a woman.\n",
      "\n",
      "\n",
      "원문 : \n",
      "  Pakistani singer Rahat Fateh Ali Khan has denied receiving any notice from the Enforcement Directorate over allegedly smuggling foreign currency out of India. \"It would have been better if the authorities would have served the notice first if any and then publicised this,\" reads a press release issued on behalf of Rahat. The statement further called the allegation \"bizarre\".\n",
      "실제 요약 : \n",
      "  Rahat Fateh Ali Khan denies getting notice for smuggling currency\n",
      "예측 요약 : \n",
      "  Pakistani singer Rahat Fateh Ali Khan has denied receiving any notice from the Enforcement Directorate over allegedly smuggling foreign currency out of India.\n",
      "\n",
      "\n",
      "원문 : \n",
      "  India recorded their lowest ODI total in New Zealand after getting all out for 92 runs in 30.5 overs in the fourth ODI at Hamilton on Thursday. Seven of India's batsmen were dismissed for single-digit scores, while their number ten batsman Yuzvendra Chahal top-scored with 18*(37). India's previous lowest ODI total in New Zealand was 108.\n",
      "실제 요약 : \n",
      "  India get all out for 92, their lowest ODI total in New Zealand\n",
      "예측 요약 : \n",
      "  India's previous lowest ODI total in New Zealand was 108.\n",
      "\n",
      "\n",
      "원문 : \n",
      "  Weeks after ex-CBI Director Alok Verma told the Department of Personnel and Training to consider him retired, the Home Ministry asked him to join work on the last day of his fixed tenure as Director on Thursday. The ministry directed him to immediately join as DG, Fire Services, the post he was transferred to after his removal as CBI chief.\n",
      "실제 요약 : \n",
      "  Govt directs Alok Verma to join work 1 day before his retirement\n",
      "예측 요약 : \n",
      "  Weeks after ex-CBI Director Alok Verma told the Department of Personnel and Training to consider him retired, the Home Ministry asked him to join work on the last day of his fixed tenure as Director on Thursday.\n",
      "\n",
      "\n",
      "원문 : \n",
      "  Andhra Pradesh CM N Chandrababu Naidu has said, \"When I met then US President Bill Clinton, I addressed him as Mr Clinton, not as 'sir'. (PM Narendra) Modi is my junior in politics...I addressed him as sir 10 times.\" \"I did this...to satisfy his ego in the hope that he will do justice to the state,\" he added.\n",
      "실제 요약 : \n",
      "  Called PM Modi 'sir' 10 times to satisfy his ego: Andhra CM\n",
      "예측 요약 : \n",
      "  Andhra Pradesh CM N Chandrababu Naidu has said, \"When I met then US President Bill Clinton, I addressed him as Mr Clinton, not as 'sir'.\n",
      "\n",
      "\n",
      "원문 : \n",
      "  Congress candidate Shafia Zubair won the Ramgarh Assembly seat in Rajasthan, by defeating BJP's Sukhwant Singh with a margin of 12,228 votes in the bypoll. With this victory, Congress has taken its total to 100 seats in the 200-member assembly. The election to the Ramgarh seat was delayed due to the death of sitting MLA and BSP candidate Laxman Singh.\n",
      "실제 요약 : \n",
      "  Cong wins Ramgarh bypoll in Rajasthan, takes total to 100 seats\n",
      "예측 요약 : \n",
      "  Congress candidate Shafia Zubair won the Ramgarh Assembly seat in Rajasthan, by defeating BJP's Sukhwant Singh with a margin of 12,228 votes in the bypoll.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize\n",
    "\n",
    "for i in range(10):\n",
    "    print(\"원문 : \\n \", orig_data['text'][i])\n",
    "    print(\"실제 요약 : \\n \", orig_data['headlines'][i])\n",
    "    print(\"예측 요약 : \\n \", summarize(orig_data['text'][i], ratio=0.5))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plain-workstation",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-senegal",
   "metadata": {},
   "source": [
    "# - 프로젝트 정리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excessive-trainer",
   "metadata": {},
   "source": [
    "### 1. 모델 :   \n",
    "\n",
    "- 모델을 학습 시켰을 때 loss는 2.3970, val_loss는 3.2395로 생각보다 loss 값들이 높게 나왔다. \n",
    "- 모델의 성능을 개선하기 위해서는 seq2seq와 어텐션의 자체의 조합을 좀 더 좋게 수정하는 방법도 있으며 빔 서치(beam search), 사전 훈련된 워드 임베딩(pre-trained word embedding), 또는 인코더 - 디코더 자체의 구조를 새로이 변경한 하는 트랜스포머(Transformer)와 같은 여러 개선 방안들이 존재한다고 한다.\n",
    "- 모델을 훈련시키는데 시간이 너무 오래 걸려서 전부 시도해보진 못했지만 시간이 된다면 전부 시도 해 봐도 좋을 것 같다.   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-franchise",
   "metadata": {},
   "source": [
    "### 2. Abstractive Summarization :   \n",
    "1)\n",
    "\n",
    "원문 : \n",
    "  three twelve boys trapped cave northern thailand days granted thai citizenship wednesday boys despite born thailand lack citizenship deprived basic benefits rights three applied citizenship cave incident    \n",
    "  \n",
    "실제 요약 : \n",
    "  boys rescued from thai cave granted citizenship    \n",
    "  \n",
    "예측 요약 : \n",
    "   thai cave rescued from thai cave to rescue boys   \n",
    "   \n",
    "- 예측된 요약과 실제 헤드라인을 비교하면 위와 같이 키워드를 잘 찾아낸 예측 요약 문장도 있다.    \n",
    "\n",
    "2)\n",
    "\n",
    "원문 : \n",
    "  nasa mars reconnaissance orbiter spotted space agency opportunity rover dust storm red planet opportunity last communicated june operating since nasa oldest active rover nasa hoping solar powered rover contact earth batteries charged exposure sunlight    \n",
    "  \n",
    "실제 요약 : \n",
    "  nasa mars spots silent rover as dust storm clears    \n",
    "  \n",
    "예측 요약 : \n",
    "   nasa rover rover on mars days to mars\n",
    "   \n",
    "- 위와 같이 키워드 단어는 잘 잡아냈지만 제대로 된 문장을 만들지 못하고 엉뚱한 내용의 예측 요약이 나오기도 했다.    \n",
    "   \n",
    "   \n",
    "타겟이 뉴스의 헤드라인이라 축약어가 많아 모델 학습이 제대로 되지 않았을 경우도 있을 것 같다. 또, 본문에서는 사용하지 않았던 단어를 헤드라인에서 사용하면서 원문과 관련이 없는 단어를 포함한 예측 요약 문장이 만들어지기도 했다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-performer",
   "metadata": {},
   "source": [
    "### 3. Extractive Summarization :   \n",
    "   \n",
    "원문 : \n",
    "  India recorded their lowest ODI total in New Zealand after getting all out for 92 runs in 30.5 overs in the fourth ODI at Hamilton on Thursday. Seven of India's batsmen were dismissed for single-digit scores, while their number ten batsman Yuzvendra Chahal top-scored with 18*(37). India's previous lowest ODI total in New Zealand was 108.   \n",
    "  \n",
    "실제 요약 : \n",
    "  India get all out for 92, their lowest ODI total in New Zealand   \n",
    "  \n",
    "예측 요약 : \n",
    "  India's previous lowest ODI total in New Zealand was 108.   \n",
    "  \n",
    "\n",
    "- 원문에서 문장을 가져오기 때문인지 Abstractive Summarization보다 예측 문장이 훨씬 매끄럽게 만들어졌다. 하지만 겉으로만 제대로 된 문장처럼 보일 뿐 실제 요약을 잘 했는지를 보면 아닌 문장도 많다.  \n",
    "\n",
    "- 부가적인 설명이 많아 실제 요약 문장보다 예측 요약 문장이 더 긴 경우가 많으며, 내용을 제대로 요약한 것이 맞나 싶을 정도로 전혀 다른 이야기를 하는 예측 요약 문장도 있다.   \n",
    "\n",
    "- 위와 같이 요약 해야 할 키워드를 잘못 잡아서 아예 다른 문장을 내 놓는 경우도 많았다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
